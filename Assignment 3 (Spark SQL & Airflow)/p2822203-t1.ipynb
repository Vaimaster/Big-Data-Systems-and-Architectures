{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"font-size: 1em\">Spark</span><span style=\"font-size: 0.8em\"> Assignment</span>\n",
    "<h3>Big Data Systems 2022-2023</h3>\n",
    "<h5>M.Sc. In Business Analytics (Part Time) 2022-2024 at Athens University of Economics and Business (A.U.E.B.)</h5>\n",
    "<hr>\n",
    "\n",
    "> Student: Panagiotis G. Vaidomarkakis<br />\n",
    "> Student I.D.: p2822203<br />\n",
    "> Tutor: Thanasis Vergoulis<br />\n",
    "> Due Date: 15/04/2023"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table Of Contents:\n",
    "* [Importing Libraries](#first-bullet)\n",
    "* [$1^{st}$ Question](#q1)\n",
    "* [$2^{nd}$ Question](#q2)\n",
    "* [$3^{rd}$ Question](#q3)\n",
    "* [$4^{th}$ Question](#q4)\n",
    "* [$5^{th}$ Question](#q5)\n",
    "* [$2^{nd}$ way to do all the calculations (Q4 & Q5)](#second-way)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries <a class=\"anchor\" id=\"first-bullet\"></a>\n",
    "In the following lines, we will import all the nessecary liblaries in order to be able to execute all the following commands. <br> First, we will run a check to see if the PC containing this Jupiter Notebook file has all the necessary libraries and if it hasn't, it will automatically download them in order to import them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pyspark is already installed.\n",
      "pyspark.sql is already installed.\n",
      "pyspark.sql.functions is already installed.\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import subprocess\n",
    "\n",
    "def install_library(lib):\n",
    "    try:\n",
    "        importlib.import_module(lib)\n",
    "        print(f'{lib} is already installed.')\n",
    "    except ImportError:\n",
    "        print(f'{lib} is not installed. Installing now...')\n",
    "        subprocess.call(['pip ', 'install ', lib])\n",
    "\n",
    "libraries = ['pyspark','pyspark.sql','pyspark.sql.functions']\n",
    "\n",
    "for lib in libraries:\n",
    "    install_library(lib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import expr, count, desc"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $1^{st}$ Question <a class=\"anchor\" id=\"q1\"></a>\n",
    "Use the *json()* function to load the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a SparkSession\n",
    "spark = SparkSession.builder.appName('Loading JSON Data').getOrCreate()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the above doesn't work, you can download Java jdk from HERE, uncomment the following cell and execute it. <br>\n",
    "After that, restart python kernel and re-execute the whole notebook until here to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# # Find and use your java_home directory. Usually is something like below.\n",
    "# JAVA_HOME = \"C:/Program Files/Eclipse Adoptium/jdk-17.0.6.10-hotspot\"\n",
    "# os.environ[\"JAVA_HOME\"] = JAVA_HOME\n",
    "# os.environ[\"PATH\"] = f\"{JAVA_HOME}/bin:{os.environ['PATH']}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _corrupt_record: string (nullable = true)\n",
      " |-- actors: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- countries: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- description: string (nullable = true)\n",
      " |-- directors: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- genre: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- imdb_url: string (nullable = true)\n",
      " |-- img_url: string (nullable = true)\n",
      " |-- languages: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- metascore: string (nullable = true)\n",
      " |-- rating: string (nullable = true)\n",
      " |-- runtime: string (nullable = true)\n",
      " |-- tagline: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- users_rating: string (nullable = true)\n",
      " |-- votes: string (nullable = true)\n",
      " |-- year: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the JSON data as a DataFrame using the json() function and print the schema to see if everything is fine\n",
    "json_movie = spark.read.json('movie.json')\n",
    "json_movie.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+--------------------+---------+--------------------+--------------------+------------------+--------------------+--------------------+-----------------+---------+------+-------+--------------------+--------------------+------------+-------+----+\n",
      "|_corrupt_record|              actors|countries|         description|           directors|             genre|            imdb_url|             img_url|        languages|metascore|rating|runtime|             tagline|               title|users_rating|  votes|year|\n",
      "+---------------+--------------------+---------+--------------------+--------------------+------------------+--------------------+--------------------+-----------------+---------+------+-------+--------------------+--------------------+------------+-------+----+\n",
      "|              [|                null|     null|                null|                null|              null|                null|                null|             null|     null|  null|   null|                null|                null|        null|   null|null|\n",
      "|           null|[Timothée Chalame...|    [USA]|A young couple ar...|       [Woody Allen]| [Comedy, Romance]|https://www.imdb....|https://m.media-a...|        [English]|       44| PG-13| 92 min|                null|A Rainy Day in Ne...|         6.6| 21,903|2019|\n",
      "|           null|[Emilia Clarke, H...|    [USA]|Creepy, terrifyin...|[Michael Escobedo...|[Horror, Thriller]|https://www.imdb....|https://m.media-a...|        [English]|     null|    18| 91 min|When it comes to ...|       Murder Manual|         2.4|    192|2020|\n",
      "|           null|[Matthew Broderic...|    [USA]|A high school wis...|       [John Hughes]|          [Comedy]|https://www.imdb....|https://m.media-a...|[English, German]|       61| PG-13|103 min|Because life is t...|Ferris Bueller's ...|         7.8|308,847|1986|\n",
      "|           null|[Robert De Niro, ...|    [USA]|A convicted rapis...|   [Martin Scorsese]| [Crime, Thriller]|https://www.imdb....|https://m.media-a...|        [English]|       73|     R|128 min|There is nothing ...|           Cape Fear|         7.3|165,628|1991|\n",
      "+---------------+--------------------+---------+--------------------+--------------------+------------------+--------------------+--------------------+-----------------+---------+------+-------+--------------------+--------------------+------------+-------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the first 5 rows of the DataFrame to verify that it was loaded correctly\n",
    "json_movie.show(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $2^{nd}$ Question <a class=\"anchor\" id=\"q2\"></a>\n",
    "Count and display the <b>number of movies</b> in the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62060"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the total number of movies\n",
    "total_movies = json_movie.count()\n",
    "total_movies"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $3^{rd}$ Question <a class=\"anchor\" id=\"q3\"></a>\n",
    "\n",
    "Count and display the <b>number of comedies</b> in the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19312"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the number of comedies\n",
    "comedy_count = json_movie.filter(\"array_contains(genre, 'Comedy')\").count()\n",
    "comedy_count"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $4^{th}$ Question <a class=\"anchor\" id=\"q4\"></a>\n",
    "\n",
    "Use the *summary()* command to display basic statistics about the *<b>“users_rating”</b>* field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|      users_rating|\n",
      "+-------+------------------+\n",
      "|  count|             62056|\n",
      "|   mean| 5.814105001933733|\n",
      "| stddev|1.3521864101722219|\n",
      "|    min|               1.0|\n",
      "|    25%|               5.0|\n",
      "|    50%|               6.0|\n",
      "|    75%|               6.7|\n",
      "|    max|               9.9|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use the summary() function to display basic statistics about the \"users_rating\" field\n",
    "json_movie.select(\"users_rating\").summary().show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $5^{th}$ Question <a class=\"anchor\" id=\"q5\"></a>\n",
    "\n",
    "Use the *groupby()* and *count()* commands to display <b>all distinct values</b> in the *<b>“rating”</b>* field and their <b>number of appearances</b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|rating   |count|\n",
      "+---------+-----+\n",
      "|null     |20669|\n",
      "|R        |11368|\n",
      "|Not Rated|8080 |\n",
      "|Approved |6419 |\n",
      "|Passed   |4488 |\n",
      "|PG-13    |3771 |\n",
      "|PG       |3286 |\n",
      "|Unrated  |1295 |\n",
      "|G        |801  |\n",
      "|TV-MA    |639  |\n",
      "|TV-14    |452  |\n",
      "|TV-PG    |268  |\n",
      "|X        |152  |\n",
      "|TV-G     |115  |\n",
      "|GP       |105  |\n",
      "|M        |41   |\n",
      "|M/PG     |27   |\n",
      "|NC-17    |22   |\n",
      "|TV-Y     |16   |\n",
      "|TV-Y7    |14   |\n",
      "|UA       |7    |\n",
      "|A        |6    |\n",
      "|Open     |4    |\n",
      "|U        |4    |\n",
      "|C        |3    |\n",
      "|AO       |2    |\n",
      "|E        |2    |\n",
      "|18       |1    |\n",
      "|(Banned) |1    |\n",
      "|TV-13    |1    |\n",
      "|All      |1    |\n",
      "+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use groupby() and count() to display all distinct values in the \"rating\" field and their number of appearances\n",
    "rating_counts = json_movie.groupBy(\"rating\").agg(count(\"*\").alias(\"count\")).orderBy(desc(\"count\"))\n",
    "rating_counts.show(31,False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $2^{nd}$ way to do all the calculations (Q4 & Q5)<a class=\"anchor\" id=\"second-way\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a temporary view of the DataFrame\n",
    "json_movie.createOrReplaceTempView(\"movies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0--------------------\n",
      " count  | 62056              \n",
      " mean   | 5.814105001933733  \n",
      " stddev | 1.3521864101722219 \n",
      " min    | 1.0                \n",
      " 25%    | 5.0                \n",
      " 50%    | 6.0                \n",
      " 75%    | 6.7                \n",
      " max    | 9.9                \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use SQL to display basic statistics about the \"users_rating\" field\n",
    "spark.sql(\"SELECT COUNT(users_rating) as count, AVG(users_rating) as mean, STDDEV(users_rating) as stddev, MIN(users_rating) as min, percentile(users_rating, 0.25) as `25%`, percentile(users_rating, 0.5) as `50%`, percentile(users_rating, 0.75) as `75%`, MAX(users_rating) as max FROM movies\").show(10,False,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|rating   |count|\n",
      "+---------+-----+\n",
      "|null     |20669|\n",
      "|R        |11368|\n",
      "|Not Rated|8080 |\n",
      "|Approved |6419 |\n",
      "|Passed   |4488 |\n",
      "|PG-13    |3771 |\n",
      "|PG       |3286 |\n",
      "|Unrated  |1295 |\n",
      "|G        |801  |\n",
      "|TV-MA    |639  |\n",
      "|TV-14    |452  |\n",
      "|TV-PG    |268  |\n",
      "|X        |152  |\n",
      "|TV-G     |115  |\n",
      "|GP       |105  |\n",
      "|M        |41   |\n",
      "|M/PG     |27   |\n",
      "|NC-17    |22   |\n",
      "|TV-Y     |16   |\n",
      "|TV-Y7    |14   |\n",
      "|UA       |7    |\n",
      "|A        |6    |\n",
      "|Open     |4    |\n",
      "|U        |4    |\n",
      "|C        |3    |\n",
      "|AO       |2    |\n",
      "|E        |2    |\n",
      "|18       |1    |\n",
      "|(Banned) |1    |\n",
      "|TV-13    |1    |\n",
      "|All      |1    |\n",
      "+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use SQL to display all distinct values in the \"rating\" field and their number of appearances\n",
    "spark.sql(\"SELECT rating, COUNT(*) as count FROM movies GROUP BY rating ORDER BY count DESC\").show(31,False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
